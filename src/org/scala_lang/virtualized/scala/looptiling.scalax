let's take matrix transpose as example:

loop(N) { i =>
loop(M) { j =>
 a(i,j) = b(j,i)
}}

transform it into this:

loop(N/tileSizeA) { i1 =>           // (assume it's a multiple)
loop(M/tileSizeB) { j1 =>
loop(tileSizeA) { i2 =>
loop(tileSizeB) { j2 =>
 val i = i1 * tileSizeA + i2       // (should also strength reduce but that's not the point here)
 val j = j1 * tileSizeB + j2
 a(i,j) = b(j,i)
}}}}

while guaranteeing that the result of the transform is well scoped. Is my understanding correct so far?

Here is problem 1: The transform seems to be unsound if M depends on i, i.e. if the shape of the loop nest is not rectangular. Value i is computed from i1 and i2 in the innermost loop but M is needed earlier. So it seems like well-scopedness cannot be guaranteed in the general case.

There seem to be a couple of different ways out of the dilemma:

1) Detect dependencies and don't apply the transform, keeping the untiled version. 

2) Detect dependencies and signal an error at staging time if loop tiling would be unsound.

3) Prevent dependencies through types. One could require loop sizes to be static values whereas loop indices would be dynamic. Since dynamic values cannot be converted to static ones (assuming we don't use run), no loop size can depend on a loop index. Having only static loop ranges seems overly restrictive though. However, any other distinction between ranges and indices would work, too, if there is no conversion. A useful way to think about this might be as a distinction between ordinal and cardinal numbers. Depending on the desired operations, loop indices might not even need to be numbers; one could treat them as values of an abstract type Index (rephrasing data structure access methods to take Index values). 

4) Prevent dependencies through coarser grained abstraction. Instead of manually nesting single-dimensional loops, one can use a multidimensional loop abstraction, similar to the SAC language (Scholz, JFP 2003; www.sac-home.org). We've also looked into doing something similar to SAC on top of Delite. The programmer specifies all dimensions at once which forces a rectangular shape:

loop(N,M) { i,j =>
...
}

or

loop(N,M,L) { (i,j,k) =>
...
}

Here, the tiling would most likely be built into the loop abstraction directly, so the following does not apply. 

------------

Assuming that one can solve the dependency issue in one way or another, here is a sketch of a possible implementation. I'm using a mutable variable to keep track of the context but shift/reset should work as well (at the expense of @cps type annotations in Scala).

// user-facing loop abstraction

def loop(n: Rep[Int])(f: Rep[Int] => Rep[Loopy]): Rep[Loopy] = {
 val n1 = n/tileSize
 val n2 = tileSize

 internalLoopNow(n1) { i1 =>
   internalLoopLater(n2) { i2 =>
     val i = i1 * n2 + i2
     f(i)
   }
 }
}

// immediately generate the first loop

def internalLoopNow(n: Rep[Int])(f: Rep[Int] => Rep[Loopy]): Rep[Loopy] = {
 val x = fresh[Int]
 val y = reify { f(x) }
 Loop(n,x,y) // create IR node right away
}

// keep track of the series of secondary loops to be generated when reaching the innermost term

var handler: Rep[Loopy] => Rep[Loopy] = (x => x)

def internalLoopLater(n: Rep[Int])(f: Rep[Int] => Rep[Loopy]): Rep[Loopy] = {
 val x = fresh[Int]
 val y = reify {
   val parentHandler = handler
   handler = (y: Rep[Loopy]) => parentHandler(Loop(n,x,y)) // push handler
   val r = f(x)
   handler = parentHandler
   r
 }
}


// innermost loop body, i.e. a(i,j) = b(j,i) term. Wrap it in the inner tiling.

def yieldBody(...): Rep[Loopy] = {
 handler(...) // traverse stack of 'later' loops, wrapping result
}


The code above is hard coded for two levels of tiling ('now' and 'later'). Generalization to arbitrary levels could be achieved by making 'handler' a list of functions and parametrizing internalLoop over the slot index. The yield method would then apply all handlers in sequence.
